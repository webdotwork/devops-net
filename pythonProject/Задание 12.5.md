# Домашнее задание к занятию "12.5 Сетевые решения CNI"
После работы с Flannel появилась необходимость обеспечить безопасность для приложения. Для этого лучше всего подойдет Calico.
## Задание 1: установить в кластер CNI плагин Calico
Для проверки других сетевых решений стоит поставить отличный от Flannel плагин — например, Calico. Требования: 
* установка производится через ansible/kubespray;
```
www@www:~$ sudo kubectl get pods -o wide -A
NAMESPACE       NAME                                      READY   STATUS    RESTARTS   AGE     IP               NODE    NOMINATED NODE   READINESS GATES
ingress-nginx   ingress-nginx-controller-4f7bc            1/1     Running   0          8h      10.233.71.1      node3   <none>           <none>
ingress-nginx   ingress-nginx-controller-4stnx            1/1     Running   0          8h      10.233.75.1      node2   <none>           <none>
ingress-nginx   ingress-nginx-controller-772rh            1/1     Running   0          8h      10.233.74.66     node4   <none>           <none>
ingress-nginx   ingress-nginx-controller-cxg8v            1/1     Running   0          8h      10.233.97.129    node5   <none>           <none>
kube-system     calico-kube-controllers-d6484b75c-dvrwt   1/1     Running   0          8h      10.233.74.65     node4   <none>           <none>
kube-system     calico-node-78jv5                         1/1     Running   0          8h      10.130.0.16      node4   <none>           <none>
kube-system     calico-node-dzwk5                         1/1     Running   0          8h      10.130.0.23      node1   <none>           <none>
kube-system     calico-node-j7s7v                         1/1     Running   0          8h      10.130.0.36      node3   <none>           <none>
kube-system     calico-node-pn96p                         1/1     Running   0          8h      10.130.0.18      node2   <none>           <none>
kube-system     calico-node-zhjbj                         1/1     Running   0          8h      10.130.0.38      node5   <none>           <none>
kube-system     coredns-588bb58b94-fzfnr                  1/1     Running   0          8h      10.233.71.2      node3   <none>           <none>
kube-system     coredns-588bb58b94-sdhjg                  1/1     Running   0          8h      10.233.102.129   node1   <none>           <none>
kube-system     dns-autoscaler-5b9959d7fc-st26m           1/1     Running   0          8h      10.233.102.130   node1   <none>           <none>
kube-system     kube-apiserver-node1                      1/1     Running   1          8h      10.130.0.23      node1   <none>           <none>
kube-system     kube-controller-manager-node1             1/1     Running   1          8h      10.130.0.23      node1   <none>           <none>
kube-system     kube-proxy-2f7cn                          1/1     Running   0          5h53m   10.130.0.18      node2   <none>           <none>
kube-system     kube-proxy-2krld                          1/1     Running   0          5h53m   10.130.0.16      node4   <none>           <none>
kube-system     kube-proxy-ks7bm                          1/1     Running   0          5h53m   10.130.0.23      node1   <none>           <none>
kube-system     kube-proxy-p8kfl                          1/1     Running   0          5h53m   10.130.0.38      node5   <none>           <none>
kube-system     kube-proxy-tltxj                          1/1     Running   0          5h53m   10.130.0.36      node3   <none>           <none>
kube-system     kube-scheduler-node1                      1/1     Running   1          8h      10.130.0.23      node1   <none>           <none>
kube-system     metrics-server-5c9dd56466-jb5j7           1/1     Running   0          8h      10.233.102.131   node1   <none>           <none>
kube-system     nginx-proxy-node2                         1/1     Running   0          8h      10.130.0.18      node2   <none>           <none>
kube-system     nginx-proxy-node3                         1/1     Running   0          8h      10.130.0.36      node3   <none>           <none>
kube-system     nginx-proxy-node4                         1/1     Running   0          8h      10.130.0.16      node4   <none>           <none>
kube-system     nginx-proxy-node5                         1/1     Running   0          8h      10.130.0.38      node5   <none>           <none>
kube-system     nodelocaldns-4wdjg                        1/1     Running   0          8h      10.130.0.36      node3   <none>           <none>
kube-system     nodelocaldns-9fx8b                        1/1     Running   0          8h      10.130.0.16      node4   <none>           <none>
kube-system     nodelocaldns-cqmv5                        1/1     Running   0          8h      10.130.0.18      node2   <none>           <none>
kube-system     nodelocaldns-k9qkt                        1/1     Running   0          8h      10.130.0.23      node1   <none>           <none>
kube-system     nodelocaldns-njm5w                        1/1     Running   0          8h      10.130.0.38      node5   <none>           <none>
```  
* после применения следует настроить политику доступа к hello-world извне. Инструкции [kubernetes.io](https://kubernetes.io/docs/concepts/services-networking/network-policies/), [Calico](https://docs.projectcalico.org/about/about-network-policy)

## Задание 2: изучить, что запущено по умолчанию
Самый простой способ — проверить командой calicoctl get <type>. Для проверки стоит получить список нод, ipPool и profile.
Требования: 
* установить утилиту calicoctl;

* получить 3 вышеописанных типа в консоли.

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.
